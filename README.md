<<<<<<< HEAD
# self-refine-loop
Self-Refine Loop
=======
# ðŸ”„ Self-Refinement Loop Project

A sophisticated system that uses machine learning critics to iteratively improve AI-generated answers through self-reflection and refinement.

## ðŸ“ Project Structure

```
refine-loop/
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ API_KEY.txt           # Gemini API key
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ data/                      # Input data
â”‚   â”œâ”€â”€ prompts.csv           # Training prompts
â”‚   â””â”€â”€ test_prompts.csv      # Test prompts
â”œâ”€â”€ models/                    # Trained models
â”‚   â”œâ”€â”€ improved_svm_critic_model.pkl
â”‚   â”œâ”€â”€ improved_svm_critic_vectorizer.pkl
â”‚   â””â”€â”€ improved_svm_text_extractor.pkl
â”œâ”€â”€ logs/                      # Output logs and results
â”œâ”€â”€ scripts/                   # Main execution scripts
â”‚   â”œâ”€â”€ run_analysis.py       # Analysis launcher
â”‚   â”œâ”€â”€ run_demo.py           # Demo launcher
â”‚   â””â”€â”€ test_improved_critic.py # Critic testing
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ core/                  # Core functionality
â”‚   â”‚   â”œâ”€â”€ critics/          # Critic implementations
â”‚   â”‚   â”œâ”€â”€ refinement/       # Refinement logic
â”‚   â”‚   â””â”€â”€ training/         # Model training
â”‚   â”œâ”€â”€ analysis/             # Analysis tools
â”‚   â”œâ”€â”€ utils/                # Utilities
â”‚   â””â”€â”€ ui/                   # User interface
â””â”€â”€ docs/                     # Documentation
    â”œâ”€â”€ README.md             # Detailed documentation
    â””â”€â”€ IMPROVEMENTS_SUMMARY.md
```

## ðŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone the repository
git clone <your-repo-url>
cd refine-loop

# Install dependencies
pip install -r config/requirements.txt

# Add your Gemini API key
echo "your-api-key-here" > config/API_KEY.txt
```

### 2. Run Analysis

```bash
# Run analysis tools
python scripts/run_analysis.py

# Or run individual analyses
python src/analysis/simple_analysis.py
python src/analysis/improve_critic.py
```

### 3. Launch Interactive Demo

```bash
# Start the Streamlit demo
python scripts/run_demo.py

# Or run directly with streamlit
streamlit run ui/demo_app.py
```

### 4. Test Critic

```bash
# Test the improved critic
python scripts/test_improved_critic.py
```

## ðŸ“Š Current Performance

- **Success Rate**: 60.7% (answers deemed sufficient by critic)
- **Average BLEU Score**: 0.64
- **Average ROUGE-L Score**: 0.813
- **Model**: Improved SVM-based critic with optimized threshold (0.67)

## ðŸ”§ Key Components

### Core Functionality (`src/core/`)
- **Critics** (`critics/`): ML-powered critic implementations
- **Refinement** (`refinement/`): Self-refinement logic and batch processing
- **Training** (`training/`): Model training utilities

### Analysis Tools (`src/analysis/`)
- Performance evaluation and visualization
- Model improvement analysis
- Results analysis and metrics

### User Interface (`ui/`)
- Interactive Streamlit demo
- Real-time refinement testing

## ðŸ“š Documentation

For detailed documentation, see the `docs/` directory:
- `docs/README.md` - Comprehensive project documentation
- `docs/IMPROVEMENTS_SUMMARY.md` - Recent improvements and next steps

## ðŸŽ¯ Features

- **Batch Processing**: Process large datasets with automatic refinement
- **ML-Powered Critics**: Trained models that evaluate answer quality
- **Advanced Feedback**: Detailed analysis with specific improvement suggestions
- **Interactive Demo**: Web interface for real-time testing
- **Comprehensive Analysis**: Tools to understand and visualize results

## ðŸ“ˆ Performance Metrics

- **Accuracy**: 96%
- **Success Rate**: 60.7%
- **False Negatives**: 5 (7.8%)
- **False Positives**: 2 (2%)
- **Improved Critic Training Accuracy**: 98.8%

The project is now organized for better maintainability and easier navigation! 
>>>>>>> 5112d03 (Initial commit: push full self-refine-loop project)
